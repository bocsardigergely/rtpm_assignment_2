{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pm4py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing log, completed traces :: 100%|██████████| 31509/31509 [00:47<00:00, 657.00it/s]\n",
      "parsing log, completed traces :: 100%|██████████| 42995/42995 [00:10<00:00, 4021.40it/s]\n"
     ]
    }
   ],
   "source": [
    "application_log = pm4py.read_xes('BPI Challenge 2017.xes')\n",
    "offer_log = pm4py.read_xes('BPI Challenge 2017 - Offer log.xes')\n",
    "\n",
    "df_application = pm4py.convert_to_dataframe(application_log)\n",
    "df_offer = pm4py.convert_to_dataframe(offer_log)\n",
    "\n",
    "df_application.to_csv('app_logs.csv')\n",
    "df_offer.to_csv('offer_logs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_application = pd.read_csv('./../../Assignment_2/Data/app_logs.csv')\n",
    "df_offer = pd.read_csv('./../../Assignment_2/Data/offer_logs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "declined_ids = list(df_application.loc[df_application['concept:name'] == 'A_Denied']['case:concept:name'].unique())\n",
    "accepted_ids = list(df_application.loc[df_application['concept:name'] == 'A_Pending']['case:concept:name'].unique())\n",
    "cancelled_ids = list(df_application.loc[df_application['concept:name'] == 'A_Cancelled']['case:concept:name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31411"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 31,509 loan applications in total\n",
    "# 98 noise \n",
    "len(declined_ids)+ len(accepted_ids)+len(cancelled_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3752, 17228, 10431)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(declined_ids), len(accepted_ids), len(cancelled_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_time(ids, i):\n",
    "    return max(df_application.loc[df_application['case:concept:name'] == ids[i]]['time:timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17228/17228 [17:38<00:00, 16.28it/s]\n"
     ]
    }
   ],
   "source": [
    "timestamp_list = []\n",
    "for i in tqdm(range(len(accepted_ids))):\n",
    "    timestamp_list.append(get_max_time(accepted_ids, i))\n",
    "#all(timestamp_list[i] <= timestamp_list[i+1] for i in range(len(timestamp_list) - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "exporting log, completed traces :: 100%|██████████| 13782/13782 [00:38<00:00, 360.82it/s]\n",
      "exporting log, completed traces :: 100%|██████████| 3446/3446 [00:09<00:00, 347.63it/s]\n"
     ]
    }
   ],
   "source": [
    "accepted_ids_w_time = sorted([(id, time) for id, time in zip(accepted_ids, timestamp_list)], key=lambda x: x[1])\n",
    "\n",
    "ids_length = len(accepted_ids_w_time)\n",
    "train_num = int(ids_length * 0.8)\n",
    "\n",
    "train_ids = [pair[0] for pair in accepted_ids_w_time[:train_num]]\n",
    "test_ids = [pair[0] for pair in accepted_ids_w_time[train_num:]]\n",
    "\n",
    "train_df = df_application.loc[df_application['case:concept:name'].isin(train_ids)]\n",
    "test_df = df_application.loc[df_application['case:concept:name'].isin(test_ids)]\n",
    "\n",
    "train_event_log = pm4py.convert_to_event_log(train_df)\n",
    "pm4py.write_xes(train_event_log, 'approved_train.xes')\n",
    "\n",
    "test_event_log = pm4py.convert_to_event_log(test_df)\n",
    "pm4py.write_xes(test_event_log, 'approved_test.xes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test(df_application, ids):\n",
    "\n",
    "    timestamp_list = []\n",
    "    for i in tqdm(range(len(ids))):\n",
    "        timestamp_list.append(get_max_time(ids, i))\n",
    "    ids_w_time = sorted([(id, time) for id, time in zip(ids, timestamp_list)], key=lambda x: x[1])\n",
    "\n",
    "    ids_length = len(ids_w_time)\n",
    "    train_num = int(ids_length * 0.8)\n",
    "\n",
    "    train_ids = ids_w_time[:train_num]\n",
    "    test_ids = ids_w_time[train_num:]\n",
    "\n",
    "    train_df = df_application.loc[df_application['case:concept:name'].isin(train_ids)]\n",
    "    test_df = df_application.loc[df_application['case:concept:name'].isin(test_ids)]\n",
    "\n",
    "    return train_df, test_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_xes(train_df, test_df, pre):\n",
    "\n",
    "    train_event_log = pm4py.convert_to_event_log(train_df)\n",
    "    pm4py.write_xes(train_event_log, f'{pre}_train.xes')\n",
    "\n",
    "    test_event_log = pm4py.convert_to_event_log(test_df)\n",
    "    pm4py.write_xes(test_event_log, f'{pre}_test.xes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 building dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_df(df):\n",
    "    \"\"\" \n",
    "    Aggregate the df of current events in the case\n",
    "\n",
    "    Output: \n",
    "        result -> could be a pandas series\n",
    "    \"\"\"\n",
    "\n",
    "    # record the timestamp of the last activity\n",
    "    result = df.iloc[0]\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_aggregate(result, df_row):\n",
    "    \"\"\" \n",
    "    When a new event happens, add the event info to the current aggregated result.\n",
    "\n",
    "    Input: \n",
    "         result: the current aggregated result\n",
    "         df_row: pandas df row representing the new event\n",
    "    Output:\n",
    "        result: the new aggregated result\n",
    "    \"\"\"\n",
    "\n",
    "    # record the timestamp of the last activity\n",
    "    result = df_row.iloc[0]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prefix_part2(df_application, app_ids, end_event, start_event='A_Accepted'):\n",
    "    \n",
    "    app_id_list = list(df_application['case:concept:name'].unique())\n",
    "\n",
    "    # TODO:\n",
    "    # create a return df\n",
    "    return_df = pd.DataFrame()\n",
    "\n",
    "    # extracting prefix for each application\n",
    "    for app_id in app_id_list:\n",
    "        \n",
    "        events_app = df_application.loc[df_application['case:concept:name'] == app_id]\n",
    "        events_app.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        cur_id = starting_row_id = events_app.loc[events_app['concept:name'] == 'A_Accepted'].index[0]\n",
    "        pre_events = events_app.iloc[:starting_row_id]\n",
    "        # TODO: \n",
    "        # aggregate events_app from row 0 to starting_row_id\n",
    "        result = aggregate_df(pre_events)\n",
    "        \n",
    "        ending_row_id = events_app.loc[events_app['concept:name'] == end_event].index[0]\n",
    "        cur_id += 1\n",
    "        \n",
    "        while cur_id < ending_row_id:\n",
    "            new_row = events_app.iloc[cur_id]\n",
    "            # TODO: \n",
    "            # add new event row info to the aggregated result\n",
    "            result = add_to_aggregate(pre_events)\n",
    "\n",
    "            # Update the return_df -> add new row\n",
    "            # target y: end_event\n",
    "\n",
    "            cur_id += 1\n",
    "\n",
    "        return return_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 building dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## similar to above, change the target y to the duration of the case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 building dataset\n",
    "---\n",
    "\n",
    "#### First XOR - test: \n",
    "\n",
    "        A_complete -> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing log, completed traces :: 100%|██████████| 8344/8344 [00:22<00:00, 370.96it/s]\n",
      "parsing log, completed traces :: 100%|██████████| 2087/2087 [00:05<00:00, 371.85it/s]\n"
     ]
    }
   ],
   "source": [
    "df_cancel_tr = pm4py.convert_to_dataframe(pm4py.read_xes('./../../Assignment_2/Data/cancelled_train.xes'))\n",
    "df_cancel_te = pm4py.convert_to_dataframe(pm4py.read_xes('./../../Assignment_2/Data/cancelled_test.xes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cancel_tr.to_csv('./../../Assignment_2/Data/cancelled_train.csv')\n",
    "df_cancel_te.to_csv('./../../Assignment_2/Data/cancelled_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 21)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_application['concept:name'].unique()), len(df_cancel_tr['concept:name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Action</th>\n",
       "      <th>org:resource</th>\n",
       "      <th>concept:name</th>\n",
       "      <th>EventOrigin</th>\n",
       "      <th>EventID</th>\n",
       "      <th>lifecycle:transition</th>\n",
       "      <th>time:timestamp</th>\n",
       "      <th>FirstWithdrawalAmount</th>\n",
       "      <th>NumberOfTerms</th>\n",
       "      <th>Accepted</th>\n",
       "      <th>MonthlyCost</th>\n",
       "      <th>Selected</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>OfferedAmount</th>\n",
       "      <th>OfferID</th>\n",
       "      <th>case:LoanGoal</th>\n",
       "      <th>case:ApplicationType</th>\n",
       "      <th>case:concept:name</th>\n",
       "      <th>case:RequestedAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>Created</td>\n",
       "      <td>User_1</td>\n",
       "      <td>A_Create Application</td>\n",
       "      <td>Application</td>\n",
       "      <td>Application_828200680</td>\n",
       "      <td>complete</td>\n",
       "      <td>2016-01-01 13:00:04.360000+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Home improvement</td>\n",
       "      <td>New credit</td>\n",
       "      <td>Application_828200680</td>\n",
       "      <td>35000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   Action org:resource          concept:name  EventOrigin  \\\n",
       "0         200  Created       User_1  A_Create Application  Application   \n",
       "\n",
       "                 EventID lifecycle:transition  \\\n",
       "0  Application_828200680             complete   \n",
       "\n",
       "                     time:timestamp  FirstWithdrawalAmount  NumberOfTerms  \\\n",
       "0  2016-01-01 13:00:04.360000+00:00                    NaN            NaN   \n",
       "\n",
       "  Accepted  MonthlyCost Selected  CreditScore  OfferedAmount OfferID  \\\n",
       "0      NaN          NaN      NaN          NaN            NaN     NaN   \n",
       "\n",
       "      case:LoanGoal case:ApplicationType      case:concept:name  \\\n",
       "0  Home improvement           New credit  Application_828200680   \n",
       "\n",
       "   case:RequestedAmount  \n",
       "0               35000.0  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cancel_tr.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0',\n",
       " 'Action',\n",
       " 'org:resource',\n",
       " 'concept:name',\n",
       " 'EventOrigin',\n",
       " 'EventID',\n",
       " 'lifecycle:transition',\n",
       " 'time:timestamp',\n",
       " 'FirstWithdrawalAmount',\n",
       " 'NumberOfTerms',\n",
       " 'Accepted',\n",
       " 'MonthlyCost',\n",
       " 'Selected',\n",
       " 'CreditScore',\n",
       " 'OfferedAmount',\n",
       " 'OfferID',\n",
       " 'case:LoanGoal',\n",
       " 'case:ApplicationType',\n",
       " 'case:concept:name',\n",
       " 'case:RequestedAmount']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_columns = list(df_cancel_tr.columns)\n",
    "all_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_attr = all_columns[all_columns.index('FirstWithdrawalAmount'):]\n",
    "\n",
    "event_attr_cat = ['org:resource', 'concept:name', 'lifecycle:transition']\n",
    "event_attr_num = ['time:timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_part4_first_xor(df_application, current_event='O_Created'):\n",
    "    \"\"\"\n",
    "    Encode original applications \n",
    "    \"\"\"\n",
    "    \n",
    "    app_id_list = list(df_application['case:concept:name'].unique())\n",
    "\n",
    "    # TODO: get all unique activities before target_event\n",
    "    # TODO: get all unique resources before target_event\n",
    "    # use abrove info to aggregate below\n",
    "\n",
    "    for app_id in app_id_list:\n",
    "\n",
    "        events_app = df_application.loc[df_application['case:concept:name'] == app_id]\n",
    "        events_app.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        starting_row_id = events_app.loc[events_app['concept:name'] == current_event].index[0]\n",
    "        pre_events = events_app.iloc[:starting_row_id]\n",
    "        # TODO: \n",
    "        # aggregate events_app from row 0 to starting_row_id\n",
    "        result = aggregate_df(pre_events)\n",
    "\n",
    "        # aggregate rows of events and append the timestamp of the target_event\n",
    "\n",
    "        # Encode each case attribute as a feature (or one-hot encode categorical case attributes)\n",
    "\n",
    "        # For each numerical event attribute, apply an aggregation function (e.g. average) over the sequence of values taken by this attribute in the prefix\n",
    "        # sum up time as one feature?\n",
    "\n",
    "        # For each categorical event attribute, encode each possible value of that attribute as a numerical feature. \n",
    "        \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "207398d66480d5b2b9abbd127913c2d129a9922276615475dd81a0eedd9eb59f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
