{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.svm import SVR\n",
    "from tqdm import tqdm \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\boris\\OneDrive\\Bureaublad\\Datascience and Entrepreneurship\\Year 2\\Semester 1\\Real-Time process mining\\prefix data\"\n",
    "df_train = pd.read_csv(path + \"\\prefix_approved_train.csv\").fillna(0)\n",
    "df_test = pd.read_csv(path + \"\\prefix_cancelled_test.csv\").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df_train):\n",
    "    df_train['first_timestamp'] = pd.to_datetime(df_train['first_timestamp'])\n",
    "\n",
    "    # day\n",
    "    df_train['Day'] = df_train['first_timestamp'].dt.day\n",
    "    # month\n",
    "    df_train['Month'] = df_train['first_timestamp'].dt.month\n",
    "    # hour\n",
    "    df_train['Start_hour'] = df_train['first_timestamp'].dt.hour\n",
    "    # minute\n",
    "    df_train['Start_minute'] = df_train['first_timestamp'].dt.minute\n",
    "    # second\n",
    "    df_train['Start_second'] = df_train['first_timestamp'].dt.second\n",
    "    # Monday is 0 and Sunday is 6\n",
    "    df_train['Start_weekday'] = df_train['first_timestamp'].dt.weekday\n",
    "    # week of the year\n",
    "    df_train['Start_week_of_year'] = df_train['first_timestamp'].dt.week\n",
    "\n",
    "    df_train.drop('first_timestamp', inplace=True, axis=1)\n",
    "\n",
    "    return df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bucketed_testing(pipe, X_train, y_train, X_test, y_test, progression):\n",
    "    X_train = X_train[X_train['case_progression'] <= progression].drop(columns = [\"case_progression\"])\n",
    "    y_train = y_train[y_train.index.isin(X_train.index)]\n",
    "    \n",
    "    X_test = X_test[X_test['case_progression'] <= progression].drop(columns = [\"case_progression\"])\n",
    "    y_test = y_test[y_test.index.isin(X_test.index)]\n",
    "\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = pipe.predict(X_test)\n",
    "\n",
    "    score = r2_score(y_pred=y_pred, y_true=y_test)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\boris\\AppData\\Local\\Temp\\ipykernel_8960\\1275838501.py:17: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n",
      "  df_train['Start_week_of_year'] = df_train['first_timestamp'].dt.week\n",
      "C:\\Users\\boris\\AppData\\Local\\Temp\\ipykernel_8960\\1275838501.py:17: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n",
      "  df_train['Start_week_of_year'] = df_train['first_timestamp'].dt.week\n"
     ]
    }
   ],
   "source": [
    "df_train = feature_engineering(df_train)\n",
    "df_test = feature_engineering(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Accepted', 'Selected', 'case:LoanGoal', 'case:ApplicationType']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_dict = {}\n",
    "dtypes_list = dict(df_train.dtypes)\n",
    "for pair in dtypes_list.items():\n",
    "    key = str(pair[1])\n",
    "    col_dict[key] = col_dict.get(key, []) + [pair[0]]\n",
    "\n",
    "col_dict[\"object\"].pop()\n",
    "col_dict['object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=['trace_duration', \"case_outcome\", \"case_progression\"], inplace=False)\n",
    "y_train = df_train['trace_duration']\n",
    "\n",
    "X_test = df_test.drop(columns=['trace_duration', \"case_outcome\", \"case_progression\"], inplace=False)\n",
    "y_test = df_test['trace_duration']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----- First algorithm -----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'columntransformer': ColumnTransformer(remainder='passthrough',\n",
       "                   transformers=[('pipeline',\n",
       "                                  Pipeline(steps=[('onehotencoder',\n",
       "                                                   OneHotEncoder())]),\n",
       "                                  ['Accepted', 'Selected', 'case:LoanGoal',\n",
       "                                   'case:ApplicationType'])]),\n",
       " 'standardscaler': StandardScaler(),\n",
       " 'randomforestregressor': RandomForestRegressor()}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_pipe = make_pipeline(OneHotEncoder())\n",
    "\n",
    "# Using categorical pipe for features A,B,C, numeric pipe otherwise\n",
    "preprocessor = make_column_transformer((categorical_pipe, col_dict['object']), remainder='passthrough')\n",
    "\n",
    "# Combine with learning algorithm in another pipeline\n",
    "\n",
    "pipe_rf = make_pipeline(preprocessor, StandardScaler(), RandomForestRegressor())\n",
    "pipe_rf.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:01<00:00, 20.39s/it]\n",
      "100%|██████████| 3/3 [01:42<00:00, 34.11s/it]\n",
      "100%|██████████| 3/3 [02:50<00:00, 56.90s/it]\n",
      "100%|██████████| 3/3 [03:38<00:00, 72.80s/it]]\n",
      "100%|██████████| 3/3 [04:48<00:00, 96.29s/it]]\n",
      "100%|██████████| 3/3 [06:03<00:00, 121.32s/it]\n",
      "100%|██████████| 3/3 [06:49<00:00, 136.44s/it]\n",
      "100%|██████████| 3/3 [08:00<00:00, 160.16s/it]\n",
      "100%|██████████| 3/3 [12:28<00:00, 249.60s/it]\n",
      "100%|██████████| 9/9 [47:24<00:00, 316.01s/it]\n"
     ]
    }
   ],
   "source": [
    "n_trees = np.arange(50, 500, 50)\n",
    "max_features = [\"sqrt\", \"log2\", 1]\n",
    "\n",
    "gridsearch_dict_forrest = {}\n",
    "\n",
    "for n in tqdm(n_trees):\n",
    "    for method in tqdm(max_features):\n",
    "        pipe_rf.set_params(randomforestregressor__n_estimators = n, randomforestregressor__max_features = method)\n",
    "        pipe_rf.fit(X_train, y_train)\n",
    "        y_pred_rf = pipe_rf.predict(X_test)\n",
    "        score = r2_score(y_pred=y_pred_rf, y_true=y_test)\n",
    "        gridsearch_dict_forrest[(n, method)] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST REGRESSOR\n",
      "best parameters were  (250, 'sqrt')  with an R2 of  0.601626117630129\n"
     ]
    }
   ],
   "source": [
    "print('RANDOM FOREST REGRESSOR')\n",
    "print(\"best parameters were \" , max(gridsearch_dict_forrest, key=gridsearch_dict_forrest.get), ' with an R2 of ', max(gridsearch_dict_forrest.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_rf.set_params(randomforestregressor__n_estimators = 450, randomforestregressor__max_features = \"sqrt\")\n",
    "pipe_rf.fit(X_train, y_train)\n",
    "y_pred_rf = pipe_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "means absolute error is:  2.5540535196788494  days \n",
      "\n",
      " R2 score is:  0.59577885914441\n"
     ]
    }
   ],
   "source": [
    "mean_abs_error_rf = (mean_absolute_error(y_true = y_test, y_pred = y_pred_rf) / (60*60*24))\n",
    "R2_rf = r2_score(y_pred = y_pred_rf, y_true = y_test)\n",
    "print(\"means absolute error is: \", mean_abs_error_rf, \" days\", \"\\n\\n\", \"R2 score is: \", R2_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize again to include case progression which is filtered on in the bucketed testing function\n",
    "X_train = df_train.drop(columns=['trace_duration', \"case_outcome\"], inplace=False)\n",
    "y_train = df_train['trace_duration']\n",
    "\n",
    "X_test = df_test.drop(columns=['trace_duration', \"case_outcome\"], inplace=False)\n",
    "y_test = df_test['trace_duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\boris\\OneDrive\\Bureaublad\\Datascience and Entrepreneurship\\Year 2\\Semester 1\\Real-Time process mining\\Assignment 2\\modeling - gergo.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/boris/OneDrive/Bureaublad/Datascience%20and%20Entrepreneurship/Year%202/Semester%201/Real-Time%20process%20mining/Assignment%202/modeling%20-%20gergo.ipynb#X36sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m res_prog_rf \u001b[39m=\u001b[39m {}\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/boris/OneDrive/Bureaublad/Datascience%20and%20Entrepreneurship/Year%202/Semester%201/Real-Time%20process%20mining/Assignment%202/modeling%20-%20gergo.ipynb#X36sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m prog:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/boris/OneDrive/Bureaublad/Datascience%20and%20Entrepreneurship/Year%202/Semester%201/Real-Time%20process%20mining/Assignment%202/modeling%20-%20gergo.ipynb#X36sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     res_prog_rf[n] \u001b[39m=\u001b[39m bucketed_testing(pipe_rf, X_train, y_train, X_test, y_test, n)\n",
      "\u001b[1;32mc:\\Users\\boris\\OneDrive\\Bureaublad\\Datascience and Entrepreneurship\\Year 2\\Semester 1\\Real-Time process mining\\Assignment 2\\modeling - gergo.ipynb Cell 15\u001b[0m in \u001b[0;36mbucketed_testing\u001b[1;34m(pipe, X_train, y_train, X_test, y_test, progression)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/boris/OneDrive/Bureaublad/Datascience%20and%20Entrepreneurship/Year%202/Semester%201/Real-Time%20process%20mining/Assignment%202/modeling%20-%20gergo.ipynb#X36sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m X_test \u001b[39m=\u001b[39m X_test[X_test[\u001b[39m'\u001b[39m\u001b[39mcase_progression\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m progression]\u001b[39m.\u001b[39mdrop(columns \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mcase_progression\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/boris/OneDrive/Bureaublad/Datascience%20and%20Entrepreneurship/Year%202/Semester%201/Real-Time%20process%20mining/Assignment%202/modeling%20-%20gergo.ipynb#X36sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m y_test \u001b[39m=\u001b[39m y_test[y_test\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39misin(X_test\u001b[39m.\u001b[39mindex)]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/boris/OneDrive/Bureaublad/Datascience%20and%20Entrepreneurship/Year%202/Semester%201/Real-Time%20process%20mining/Assignment%202/modeling%20-%20gergo.ipynb#X36sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m pipe\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/boris/OneDrive/Bureaublad/Datascience%20and%20Entrepreneurship/Year%202/Semester%201/Real-Time%20process%20mining/Assignment%202/modeling%20-%20gergo.ipynb#X36sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m y_pred \u001b[39m=\u001b[39m pipe\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/boris/OneDrive/Bureaublad/Datascience%20and%20Entrepreneurship/Year%202/Semester%201/Real-Time%20process%20mining/Assignment%202/modeling%20-%20gergo.ipynb#X36sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m score \u001b[39m=\u001b[39m r2_score(y_pred\u001b[39m=\u001b[39my_pred, y_true\u001b[39m=\u001b[39my_test)\n",
      "File \u001b[1;32mc:\\Users\\boris\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:382\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    381\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[1;32m--> 382\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_final_estimator\u001b[39m.\u001b[39;49mfit(Xt, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_last_step)\n\u001b[0;32m    384\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\boris\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:476\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    465\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[0;32m    466\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m    467\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    468\u001b[0m ]\n\u001b[0;32m    470\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    475\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 476\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    477\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m    478\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    479\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    480\u001b[0m )(\n\u001b[0;32m    481\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    482\u001b[0m         t,\n\u001b[0;32m    483\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[0;32m    484\u001b[0m         X,\n\u001b[0;32m    485\u001b[0m         y,\n\u001b[0;32m    486\u001b[0m         sample_weight,\n\u001b[0;32m    487\u001b[0m         i,\n\u001b[0;32m    488\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[0;32m    489\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    490\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m    491\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[0;32m    492\u001b[0m     )\n\u001b[0;32m    493\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[0;32m    494\u001b[0m )\n\u001b[0;32m    496\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    497\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\boris\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1044\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1046\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1047\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1050\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\boris\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\boris\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    780\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\boris\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\boris\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\boris\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\boris\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\boris\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\boris\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:189\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    187\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[1;32m--> 189\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    190\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    191\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\boris\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:1342\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1313\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m   1314\u001b[0m     \u001b[39m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1315\u001b[0m \n\u001b[0;32m   1316\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1339\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1340\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1342\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m   1343\u001b[0m         X,\n\u001b[0;32m   1344\u001b[0m         y,\n\u001b[0;32m   1345\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1346\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m   1347\u001b[0m     )\n\u001b[0;32m   1348\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\boris\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:458\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    448\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    449\u001b[0m         splitter,\n\u001b[0;32m    450\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    455\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    456\u001b[0m     )\n\u001b[1;32m--> 458\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[0;32m    460\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[0;32m    461\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "pipe_rf.set_params(randomforestregressor__n_estimators = 250, randomforestregressor__max_features = \"sqrt\")\n",
    "prog = np.arange(0.0, 1, 0.05)\n",
    "\n",
    "# store the results for different min_sim\n",
    "res_prog_rf = {}\n",
    "for n in prog:\n",
    "\n",
    "    res_prog_rf[n] = bucketed_testing(pipe_rf, X_train, y_train, X_test, y_test, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme()\n",
    "\n",
    "df_progression_results_rf = pd.DataFrame.from_dict(res_prog_rf, orient='index').reset_index().rename(\n",
    "    columns={\"index\": \"case_progression\", 0: \"R2\"})\n",
    "\n",
    "sns.lineplot(\n",
    "    data = df_progression_results_rf,\n",
    "    x = \"case_progression\", y = \"R2\", markers=True, dashes=False\n",
    ").set(title = \"Predictive performanc over case duration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------ Second algorithm -----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'columntransformer': ColumnTransformer(remainder='passthrough',\n",
       "                   transformers=[('pipeline',\n",
       "                                  Pipeline(steps=[('onehotencoder',\n",
       "                                                   OneHotEncoder())]),\n",
       "                                  ['Accepted', 'Selected', 'case:LoanGoal',\n",
       "                                   'case:ApplicationType'])]),\n",
       " 'standardscaler': StandardScaler(),\n",
       " 'svr': SVR(cache_size=1000)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_pipe = make_pipeline(OneHotEncoder())\n",
    "\n",
    "# Using categorical pipe for features A,B,C, numeric pipe otherwise\n",
    "preprocessor = make_column_transformer((categorical_pipe, col_dict['object']), remainder='passthrough')\n",
    "\n",
    "# Combine with learning algorithm in another pipeline\n",
    "\n",
    "pipe_svr = make_pipeline(preprocessor, StandardScaler(), SVR(cache_size = 1000))\n",
    "pipe_svr.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [3:52:02<00:00, 4640.73s/it]\n",
      "100%|██████████| 3/3 [3:43:03<00:00, 4461.25s/it]/it]\n",
      "100%|██████████| 3/3 [3:43:12<00:00, 4464.21s/it]/it]\n",
      "100%|██████████| 3/3 [3:43:00<00:00, 4460.05s/it]/it]\n",
      "100%|██████████| 3/3 [3:00:20<00:00, 3606.88s/it]/it]\n",
      "100%|██████████| 5/5 [18:01:39<00:00, 12979.88s/it]  \n"
     ]
    }
   ],
   "source": [
    "regularization = np.arange(0.5, 1, 0.1)\n",
    "kernels = [\"poly\", \"rbf\", \"sigmoid\"]\n",
    "\n",
    "gridsearch_dict_SVR = {} \n",
    "\n",
    "for penalty in tqdm(regularization):\n",
    "    for kernel in tqdm(kernels):\n",
    "        pipe_svr.set_params(svr__C = penalty, svr__kernel = kernel)\n",
    "        pipe_svr.fit(X_train, y_train)\n",
    "        y_pred_svr = pipe_svr.predict(X_test)\n",
    "        score = r2_score(y_pred=y_pred_svr, y_true=y_test)\n",
    "        gridsearch_dict_SVR[(penalty, kernel)] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0.5, 'poly'): -0.08825349743945732,\n",
       " (0.5, 'rbf'): -0.0884056182880113,\n",
       " (0.5, 'sigmoid'): -0.08706205018329505,\n",
       " (0.6, 'poly'): -0.09217156864682208,\n",
       " (0.6, 'rbf'): -0.08783426656281623,\n",
       " (0.6, 'sigmoid'): -0.086241562606167,\n",
       " (0.7, 'poly'): -0.09757957065037481,\n",
       " (0.7, 'rbf'): -0.08728515614193477,\n",
       " (0.7, 'sigmoid'): -0.08541347035376567,\n",
       " (0.7999999999999999, 'poly'): -0.1075448952106215,\n",
       " (0.7999999999999999, 'rbf'): -0.08674882910251913,\n",
       " (0.7999999999999999, 'sigmoid'): -0.08460601734522033,\n",
       " (0.8999999999999999, 'poly'): -0.11950028905348242,\n",
       " (0.8999999999999999, 'rbf'): -0.08618529151780452,\n",
       " (0.8999999999999999, 'sigmoid'): -0.08380953517085321}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_dict_SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUPPORT VECTOR REGRESSOR\n",
      "best parameters were  (0.8999999999999999, 'sigmoid')  with an R2 of  -0.08380953517085321\n"
     ]
    }
   ],
   "source": [
    "print('SUPPORT VECTOR REGRESSOR')\n",
    "print(\"best parameters were \" , max(gridsearch_dict_SVR, key=gridsearch_dict_SVR.get), ' with an R2 of ', max(gridsearch_dict_SVR.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_svr.set_params(svr__C = 0.9, svr__kernel = \"sigmoid\", svr__cache_size = 2000)\n",
    "pipe_svr.fit(X_train, y_train)\n",
    "y_pred_svr = pipe_svr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_abs_error_svr = (mean_absolute_error(y_true = y_test, y_pred = y_pred_svr) / (60*60*24))\n",
    "R2_svr = r2_score(y_pred = y_pred_svr, y_true = y_test)\n",
    "print(\"means absolute error is: \", mean_abs_error_svr, \" days\", \"\\n\\n\", \"R2 score is: \", R2_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize again to include case progression which is filtered on in the bucketed testing function\n",
    "X_train = df_train.drop(columns=['trace_duration', \"case_outcome\"], inplace=False)\n",
    "y_train = df_train['trace_duration']\n",
    "\n",
    "X_test = df_test.drop(columns=['trace_duration', \"case_outcome\"], inplace=False)\n",
    "y_test = df_test['trace_duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "pipe_svr.set_params(svr__C = 0.9, svr__kernel = \"sigmoid\")\n",
    "prog = np.arange(0.0, 1, 0.05)\n",
    "\n",
    "# store the results for different min_sim\n",
    "res_prog_svr = {}\n",
    "for n in tqdm(prog):\n",
    "\n",
    "    res_prog_svr[n] = bucketed_testing(pipe_svr, X_train, y_train, X_test, y_test, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme()\n",
    "\n",
    "df_progression_results_svr = pd.DataFrame.from_dict(res_prog_svr, orient='index').reset_index().rename(\n",
    "    columns={\"index\": \"case_progression\", 0: \"R2\"})\n",
    "\n",
    "sns.lineplot(\n",
    "    data = df_progression_results_svr,\n",
    "    x = \"case_progression\", y = \"R2\", markers=True, dashes=False\n",
    ").set(title = \"Predictive performanc over case duration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bdfd0ab590d37ad3e186c66b82c017e01055655de06222048609fc9f6dee6823"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
